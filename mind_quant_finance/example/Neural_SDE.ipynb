{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.nn.layer import Dense, CellList\n",
    "from mindspore import Tensor\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as P\n",
    "from typing import Callable, List\n",
    "from mindspore import ms_function\n",
    "import mindspore.numpy as mnp\n",
    "\n",
    "\n",
    "\n",
    "@ms_function\n",
    "def _identity(x: Tensor):\n",
    "    return x \n",
    "\n",
    "class MLP(nn.Cell):\n",
    "    layers: CellList\n",
    "    activation: Callable\n",
    "    final_activation: Callable\n",
    "    depth: int\n",
    "    in_size: int\n",
    "    out_size: int\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_size: int,\n",
    "        out_size: int,\n",
    "        width_size: int,\n",
    "        depth: int,\n",
    "        activation: Callable = nn.ReLU(),\n",
    "        final_activation: Callable = _identity,\n",
    "        has_bias=False\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        layers = CellList()\n",
    "        if depth == 0:\n",
    "            layers.append(Dense(in_size, out_size, has_bias=has_bias))\n",
    "        else:\n",
    "            layers.append(Dense(in_size, width_size, has_bias=has_bias))\n",
    "            for i in range(depth - 1):\n",
    "                layers.append(Dense(width_size, width_size, has_bias=has_bias))\n",
    "            layers.append(Dense(width_size, out_size, has_bias=has_bias))\n",
    "        self.layers = layers\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        self.width_size = width_size\n",
    "        self.depth = depth\n",
    "        self.activation = activation\n",
    "        self.final_activation = final_activation\n",
    "    \n",
    "\n",
    "    def construct(self, x: Tensor):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x)\n",
    "            x = self.activation(x)\n",
    "        x = self.layers[-1](x)\n",
    "        x = self.final_activation(x)\n",
    "        return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP(3, 4, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mnp.ones(shape=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 4], dtype=Float32, value=\n",
       "[[-2.48252741e-06,  1.02177510e-05, -2.74512354e-06,  4.89074068e-07]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mindspore_py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46762f94579a4550673c2171cae75b7f4de13321337641ec98bbf3a9e19b78df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
